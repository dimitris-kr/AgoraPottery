{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Basics",
   "id": "f098611f98db3b26"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Imports",
   "id": "4b30897c2f04ccc1"
  },
  {
   "metadata": {
    "id": "_TbRWQlSGDn5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1740652738136,
     "user_tz": -120,
     "elapsed": 9399,
     "user": {
      "displayName": "Dimitris Krikonis",
      "userId": "11139468322740823660"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-04-13T17:51:04.361299Z",
     "start_time": "2025-04-13T17:51:04.358291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ],
   "id": "61d47ad6259f4b7d",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Working Directory Path",
   "id": "5e36eabbbd29621a"
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ivyMTcsBkMF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1740652760032,
     "user_tz": -120,
     "elapsed": 21894,
     "user": {
      "displayName": "Dimitris Krikonis",
      "userId": "11139468322740823660"
     }
    },
    "outputId": "624f3a35-7661-4b3b-9481-94760dfd79ab",
    "ExecuteTime": {
     "end_time": "2025-04-13T17:51:04.368326Z",
     "start_time": "2025-04-13T17:51:04.365816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Google Drive Path for Running on Colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# path = \"drive/MyDrive/MSc Thesis/\""
   ],
   "id": "713fbe2103d82879",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T19:16:35.029474Z",
     "start_time": "2025-04-13T19:16:35.026513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Local Path for Running Locally\n",
    "path = \"./data/\"\n",
    "path_images = path + \"images/\"\n",
    "path_export = path + \"features/\"\n",
    "os.makedirs(path_export, exist_ok=True)"
   ],
   "id": "24561e9f685a17ff",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Read Pre-Processed Data",
   "id": "ebb8ee365ef0697"
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vMGMVkIgF-en",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1740652760840,
     "user_tz": -120,
     "elapsed": 808,
     "user": {
      "displayName": "Dimitris Krikonis",
      "userId": "11139468322740823660"
     }
    },
    "outputId": "3a47fe5c-f36d-4df0-dc35-6a6008ee726f",
    "ExecuteTime": {
     "end_time": "2025-04-13T17:51:04.388879Z",
     "start_time": "2025-04-13T17:51:04.376845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(path + 'agora12_data_pp.csv')\n",
    "data"
   ],
   "id": "2091ea2ebc3ad806",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                               Id  \\\n",
       "0        Agora:Object:Agora XII:1   \n",
       "1        Agora:Object:Agora XII:2   \n",
       "2        Agora:Object:Agora XII:3   \n",
       "3        Agora:Object:Agora XII:4   \n",
       "4        Agora:Object:Agora XII:5   \n",
       "...                           ...   \n",
       "1985  Agora:Object:Agora XII:2036   \n",
       "1986  Agora:Object:Agora XII:2037   \n",
       "1987  Agora:Object:Agora XII:2038   \n",
       "1988  Agora:Object:Agora XII:2039   \n",
       "1989  Agora:Object:Agora XII:2040   \n",
       "\n",
       "                                               FullText  \\\n",
       "0     foot missing. offset neck and echinoid mouth; ...   \n",
       "1     spreading ring foot with torus outer and conve...   \n",
       "2     flaring ring foot. torus mouth. ridge at junct...   \n",
       "3     ring foot. echinoid mouth inset from neck and ...   \n",
       "4     echinus ring foot. torus mouth; strap handles....   \n",
       "...                                                 ...   \n",
       "1985  fragment of rim and floor with handle. deep ba...   \n",
       "1986  handles missing. basin and lid; handles probab...   \n",
       "1987  small series. plain flat-topped rim; flaring b...   \n",
       "1988  small series. rim flat on top, roughly moulded...   \n",
       "1989  stand and floor fragment. lower edge of stand ...   \n",
       "\n",
       "                     ImageFilename  StartYear  EndYear  \n",
       "0     Agora_Image_2012.54.1450.jpg       -575     -550  \n",
       "1                              NaN       -525     -500  \n",
       "2                              NaN       -500     -500  \n",
       "3                              NaN       -500     -500  \n",
       "4     Agora_Image_2012.27.0009.jpg       -525     -500  \n",
       "...                            ...        ...      ...  \n",
       "1985                           NaN       -350     -320  \n",
       "1986  Agora_Image_2012.55.1261.jpg       -350     -301  \n",
       "1987  Agora_Image_2012.25.0184.jpg       -435     -425  \n",
       "1988  Agora_Image_2012.55.1268.jpg       -375     -325  \n",
       "1989                           NaN       -400     -300  \n",
       "\n",
       "[1990 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>FullText</th>\n",
       "      <th>ImageFilename</th>\n",
       "      <th>StartYear</th>\n",
       "      <th>EndYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agora:Object:Agora XII:1</td>\n",
       "      <td>foot missing. offset neck and echinoid mouth; ...</td>\n",
       "      <td>Agora_Image_2012.54.1450.jpg</td>\n",
       "      <td>-575</td>\n",
       "      <td>-550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agora:Object:Agora XII:2</td>\n",
       "      <td>spreading ring foot with torus outer and conve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-525</td>\n",
       "      <td>-500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agora:Object:Agora XII:3</td>\n",
       "      <td>flaring ring foot. torus mouth. ridge at junct...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-500</td>\n",
       "      <td>-500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agora:Object:Agora XII:4</td>\n",
       "      <td>ring foot. echinoid mouth inset from neck and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-500</td>\n",
       "      <td>-500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agora:Object:Agora XII:5</td>\n",
       "      <td>echinus ring foot. torus mouth; strap handles....</td>\n",
       "      <td>Agora_Image_2012.27.0009.jpg</td>\n",
       "      <td>-525</td>\n",
       "      <td>-500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>Agora:Object:Agora XII:2036</td>\n",
       "      <td>fragment of rim and floor with handle. deep ba...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-350</td>\n",
       "      <td>-320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>Agora:Object:Agora XII:2037</td>\n",
       "      <td>handles missing. basin and lid; handles probab...</td>\n",
       "      <td>Agora_Image_2012.55.1261.jpg</td>\n",
       "      <td>-350</td>\n",
       "      <td>-301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>Agora:Object:Agora XII:2038</td>\n",
       "      <td>small series. plain flat-topped rim; flaring b...</td>\n",
       "      <td>Agora_Image_2012.25.0184.jpg</td>\n",
       "      <td>-435</td>\n",
       "      <td>-425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>Agora:Object:Agora XII:2039</td>\n",
       "      <td>small series. rim flat on top, roughly moulded...</td>\n",
       "      <td>Agora_Image_2012.55.1268.jpg</td>\n",
       "      <td>-375</td>\n",
       "      <td>-325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>Agora:Object:Agora XII:2040</td>\n",
       "      <td>stand and floor fragment. lower edge of stand ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-400</td>\n",
       "      <td>-300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1990 rows √ó 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature Extraction from Text Data",
   "id": "813c057416017478"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### TF-IDF\n",
    "\n",
    "‚úî **Best for:** Traditional ML models (Random Forest, XGBoost, SVM).\n",
    "\n",
    "‚úî **Why use it?**\n",
    "- Captures word importance across the dataset.\n",
    "- Works well with structured text like archaeological descriptions.\n",
    "- Computationally efficient, doesn‚Äôt require a large dataset.\n",
    "\n",
    "üîπ **Pros:** Fast, interpretable, low resource usage.\n",
    "\n",
    "üîπ **Cons:** Doesn‚Äôt capture word relationships (e.g., \"small bowl\" and \"bowl small\" are treated differently)."
   ],
   "id": "c5a2794b0f4e0eba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T17:51:04.409811Z",
     "start_time": "2025-04-13T17:51:04.407009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=300,  # Use top 300 important words\n",
    "    stop_words='english'\n",
    ")"
   ],
   "id": "af781d5d5d48a409",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T17:51:04.484466Z",
     "start_time": "2025-04-13T17:51:04.429823Z"
    }
   },
   "cell_type": "code",
   "source": [
    " # Vectorize the text using TF-IDF\n",
    "tfidf_vectors = vectorizer.fit_transform(data[\"FullText\"]).toarray()\n",
    "\n",
    "# Convert to DataFrame\n",
    "tfidf_vectors = pd.DataFrame(tfidf_vectors, columns=[f\"F{i}\" for i in range(300)])\n",
    "tfidf_vectors"
   ],
   "id": "6d62093f7736be8f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            F0   F1   F2        F3   F4   F5   F6        F7   F8   F9  ...  \\\n",
       "0     0.000000  0.0  0.0  0.112297  0.0  0.0  0.0  0.136783  0.0  0.0  ...   \n",
       "1     0.198781  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
       "2     0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
       "3     0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
       "4     0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
       "...        ...  ...  ...       ...  ...  ...  ...       ...  ...  ...  ...   \n",
       "1985  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
       "1986  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
       "1987  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
       "1988  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
       "1989  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
       "\n",
       "          F290      F291      F292  F293  F294  F295      F296  F297  \\\n",
       "0     0.057870  0.000000  0.000000   0.0   0.0   0.0  0.000000   0.0   \n",
       "1     0.091611  0.000000  0.000000   0.0   0.0   0.0  0.000000   0.0   \n",
       "2     0.150587  0.000000  0.000000   0.0   0.0   0.0  0.000000   0.0   \n",
       "3     0.066499  0.000000  0.000000   0.0   0.0   0.0  0.000000   0.0   \n",
       "4     0.000000  0.000000  0.000000   0.0   0.0   0.0  0.000000   0.0   \n",
       "...        ...       ...       ...   ...   ...   ...       ...   ...   \n",
       "1985  0.000000  0.000000  0.226684   0.0   0.0   0.0  0.000000   0.0   \n",
       "1986  0.000000  0.000000  0.165994   0.0   0.0   0.0  0.000000   0.0   \n",
       "1987  0.000000  0.150721  0.000000   0.0   0.0   0.0  0.000000   0.0   \n",
       "1988  0.000000  0.195492  0.000000   0.0   0.0   0.0  0.000000   0.0   \n",
       "1989  0.085868  0.000000  0.000000   0.0   0.0   0.0  0.161437   0.0   \n",
       "\n",
       "          F298  F299  \n",
       "0     0.000000   0.0  \n",
       "1     0.000000   0.0  \n",
       "2     0.000000   0.0  \n",
       "3     0.000000   0.0  \n",
       "4     0.000000   0.0  \n",
       "...        ...   ...  \n",
       "1985  0.000000   0.0  \n",
       "1986  0.000000   0.0  \n",
       "1987  0.221368   0.0  \n",
       "1988  0.000000   0.0  \n",
       "1989  0.000000   0.0  \n",
       "\n",
       "[1990 rows x 300 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F0</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F290</th>\n",
       "      <th>F291</th>\n",
       "      <th>F292</th>\n",
       "      <th>F293</th>\n",
       "      <th>F294</th>\n",
       "      <th>F295</th>\n",
       "      <th>F296</th>\n",
       "      <th>F297</th>\n",
       "      <th>F298</th>\n",
       "      <th>F299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.198781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.221368</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.195492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.161437</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1990 rows √ó 300 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T17:53:48.298577Z",
     "start_time": "2025-04-13T17:53:48.168826Z"
    }
   },
   "cell_type": "code",
   "source": "tfidf_vectors.to_csv(path_export + 'text_tfidf_vectors.csv', index=False, encoding='utf-8', sep=',', header=True)",
   "id": "7b4cc7259b0fc3af",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### BERT\n",
    "\n",
    " Pretrained BERT models convert text (pottery descriptions, classifications, and dimensions) into dense numerical embeddings.\n",
    "\n",
    "‚úÖ Pros:\n",
    "- Fast with low compute cost.\n",
    "- Good for small datasets.\n",
    "- Understands context better than TF-IDF\n",
    "- Combines perfectly with images, dimensions, deposits for mixed models.\n",
    "\n",
    "‚ùå Cons:\n",
    "- Doesn‚Äôt adapt BERT to archaeology-specific vocabulary."
   ],
   "id": "f02a85c600e7ad24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ca983b2434b7711"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T16:31:03.530514Z",
     "start_time": "2025-04-13T16:30:59.276112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import os\n",
    "\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\""
   ],
   "id": "fadec6f2a2728c80",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T16:31:03.561290Z",
     "start_time": "2025-04-13T16:31:03.546378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())  # True if CUDA is installed\n",
    "print(torch.cuda.get_device_name(0))  # Should show NVIDIA GeForce RTX 4080"
   ],
   "id": "e524ceca40a48782",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n",
      "True\n",
      "NVIDIA GeForce RTX 4080\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "918e6cb3709a4d1c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Load BERT**\n",
    "- \"bert-base-uncased\" is the standard English BERT ‚Äî lowercased, pretrained on Wikipedia and BooksCorpus.\n",
    "- Tokenizer will convert your text into token IDs and attention masks.\n",
    "- Model will turn those token IDs into a vector representation (embedding)."
   ],
   "id": "2c252fe9321d56a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T16:31:04.818420Z",
     "start_time": "2025-04-13T16:31:03.765247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the tokenizer and BERT model\n",
    "model_name = \"bert-base-uncased\"  # \"sentence-transformers/all-MiniLM-L6-v2\" for optimized embeddings\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ],
   "id": "9087073fe22466d",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Text to BERT Embedding Function**\n",
    "- The function takes raw text and returns a 768-dimensional vector (BERT‚Äôs hidden size).\n",
    "- `tokenizer` converts text to token IDs and attention masks.\n",
    "- `inputs = {key: val.to(\"cuda\")}` moves all input tensors to GPU.\n",
    "- ``model.to(\"cuda\")`` ensures the model uses the GPU too.\n",
    "- ``with torch.no_grad()`` tells PyTorch: no gradients needed (inference mode, not training).\n",
    "- ``outputs.last_hidden_state[:, 0, :]``: grabs the first token‚Äôs embedding ([CLS]) which BERT uses to summarize the whole sequence."
   ],
   "id": "ed7c4db4138e24c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T17:43:30.750266Z",
     "start_time": "2025-04-13T17:43:30.746651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_bert_embedding_tensor(text):\n",
    "    if pd.isna(text) or text.strip() == \"\":\n",
    "        return torch.zeros(768).to(\"cuda\")  # Fallback for empty text\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "\n",
    "    # Move each tensor in the dict to CUDA\n",
    "    inputs = {key: val.to(\"cuda\") for key, val in inputs.items()}\n",
    "    model.to(\"cuda\")  # Make sure the model is on CUDA too!\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    bert_embedding_tensor = outputs.last_hidden_state[:, 0, :].squeeze()\n",
    "    return bert_embedding_tensor"
   ],
   "id": "909ceebfea595b0f",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**BERT Embedding Tensors**\n",
    "\n",
    "Apply text to BERT embedding tensor transformation to all records"
   ],
   "id": "98496166b1c05f67"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T17:43:39.480390Z",
     "start_time": "2025-04-13T17:43:31.148161Z"
    }
   },
   "cell_type": "code",
   "source": "bert_embedding_tensor_list = data[\"FullText\"].apply(get_bert_embedding_tensor).tolist()",
   "id": "55684d0fbffdc016",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Stack tensors into single tensor for neural network pipelines",
   "id": "1e3e79e058aed35f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T17:56:37.795425Z",
     "start_time": "2025-04-13T17:56:37.792108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bert_embedding_tensors = torch.stack(bert_embedding_tensor_list)\n",
    "bert_embedding_tensors.shape"
   ],
   "id": "951c692284889af0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1990, 768])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T17:59:22.188031Z",
     "start_time": "2025-04-13T17:59:22.180575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.save(bert_embedding_tensors, path_export + \"text_bert_embedding_tensors.pt\")\n",
    "# bert_embedding_tensors = torch.load(path + \"text_bert_embedding_tensors.pt\")"
   ],
   "id": "4559800e6fd8ac71",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**BERT Embedding Vectors**\n",
    "\n",
    "Convert tensors to 2D NumPy Matrix for classic ML methods"
   ],
   "id": "f2ebed39562adc4e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T17:43:39.518831Z",
     "start_time": "2025-04-13T17:43:39.483628Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1990, 768)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35,
   "source": [
    "bert_embedding_vectors = [tensor.cpu().numpy() for tensor in bert_embedding_tensor_list]\n",
    "bert_embedding_vectors = np.vstack(bert_embedding_vectors)\n",
    "bert_embedding_vectors = pd.DataFrame(\n",
    "    bert_embedding_vectors,\n",
    "    columns=[f\"F{i}\" for i in range(bert_embedding_vectors.shape[1])]\n",
    ")\n",
    "bert_embedding_vectors.shape"
   ],
   "id": "fad5bf909709e53a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T17:56:08.880851Z",
     "start_time": "2025-04-13T17:56:08.351173Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 48,
   "source": "bert_embedding_vectors.to_csv(path_export + 'text_bert_embedding_vectors.csv', index=False, encoding='utf-8', sep=',',header=True)",
   "id": "a63a2bb94f7e8bb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Fine-Tuning BERT\n",
    "\n",
    "‚úÖ Pros:\n",
    "- BERT learns from the specific archaeology vocabulary of the data.\n",
    "- Usually higher performance for text-heavy tasks.\n",
    "\n",
    "‚ùå Cons:\n",
    "- Takes longer to train.\n",
    "- Harder to combine with images."
   ],
   "id": "a28822d42febf7de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T18:15:22.591690Z",
     "start_time": "2025-04-13T18:15:22.589005Z"
    }
   },
   "cell_type": "code",
   "source": "#### TO DO: TRY FINE TUNING ######",
   "id": "ffc804856d7c585",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature Extraction from Images",
   "id": "4dbdb744bde67025"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Pretrained CNNs (Transfer Learning)\n",
    "\n",
    "Pretrained Convolutional Neural Networks (CNNs) trained on ImageNet (millions of images) to extract feature vectors.\n",
    "\n",
    "‚úÖ Pros:\n",
    "- Good for small dataset, no training needed.\n",
    "- Despite being trained on everyday objects, they can recognize visual patterns of pottery like:\n",
    "  - shape contours,\n",
    "  - textures,\n",
    "  - edges and symmetries\n",
    "\n",
    "‚ùå Cons:\n",
    "- Not specialized to archaeological images.\n"
   ],
   "id": "2edb274003f97eb7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### ResNet",
   "id": "c0464e4f8861ceee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T19:24:00.849850Z",
     "start_time": "2025-04-13T19:24:00.847350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50\n",
    "from PIL import Image"
   ],
   "id": "b7d608b5e35325bf",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T19:18:20.059568Z",
     "start_time": "2025-04-13T19:18:20.056568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resnet_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ],
   "id": "581359c7cb73a760",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T19:22:07.396126Z",
     "start_time": "2025-04-13T19:21:54.926987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resnet = resnet50(weights='DEFAULT')\n",
    "resnet = torch.nn.Sequential(*list(resnet.children())[:-1])  # Remove classification layer\n",
    "resnet.eval().cuda()"
   ],
   "id": "2f8d051694f4fcd4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to C:\\Users\\dimit/.cache\\torch\\hub\\checkpoints\\resnet50-11ad3fa6.pth\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97.8M/97.8M [00:12<00:00, 8.40MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T19:24:07.389530Z",
     "start_time": "2025-04-13T19:24:07.386406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_resnet_features(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image_tensor = resnet_transform(image).unsqueeze(0).cuda()\n",
    "    with torch.no_grad():\n",
    "        features = resnet(image_tensor).squeeze().cpu().numpy()\n",
    "    return features  # Shape: 2048"
   ],
   "id": "72262b237ce1086b",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Vision Transformers (ViT)\n",
    "\n",
    "Transformer-based model from Hugging Face that treats images like sequences (patches).\n",
    "\n",
    "- advanced alternative\n",
    "- modern / cutting-edge method\n",
    "\n"
   ],
   "id": "8794e6d45191280"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "521ebfe667d42261"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Fine-Tuning Pretrained CNNs (End-to-End Training)\n",
    "\n",
    "‚úÖ Pros:\n",
    "- Learns specifically from images with pottery\n",
    "- Potentially higher accuracy\n",
    "\n",
    "‚ùå Cons:\n",
    "- Requires large dataset and more computing power\n",
    "- Risk of overfitting with only ~500 images.\n",
    "\n"
   ],
   "id": "8ff92b061058e444"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "21fd016741c7077"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
