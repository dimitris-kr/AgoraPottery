{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Basics",
   "id": "f098611f98db3b26"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Imports",
   "id": "4b30897c2f04ccc1"
  },
  {
   "metadata": {
    "id": "_TbRWQlSGDn5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1740652738136,
     "user_tz": -120,
     "elapsed": 9399,
     "user": {
      "displayName": "Dimitris Krikonis",
      "userId": "11139468322740823660"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-04-14T19:14:07.348336Z",
     "start_time": "2025-04-14T19:14:07.345308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ],
   "id": "61d47ad6259f4b7d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Working Directory Path",
   "id": "5e36eabbbd29621a"
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ivyMTcsBkMF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1740652760032,
     "user_tz": -120,
     "elapsed": 21894,
     "user": {
      "displayName": "Dimitris Krikonis",
      "userId": "11139468322740823660"
     }
    },
    "outputId": "624f3a35-7661-4b3b-9481-94760dfd79ab",
    "ExecuteTime": {
     "end_time": "2025-04-14T19:14:07.365540Z",
     "start_time": "2025-04-14T19:14:07.363367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Google Drive Path for Running on Colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# path = \"drive/MyDrive/MSc Thesis/\""
   ],
   "id": "713fbe2103d82879",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:14:07.372292Z",
     "start_time": "2025-04-14T19:14:07.368780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Local Path for Running Locally\n",
    "path = \"./data/\"\n",
    "path_images = path + \"images/\"\n",
    "path_export = path + \"features/\"\n",
    "os.makedirs(path_export, exist_ok=True)"
   ],
   "id": "24561e9f685a17ff",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Read Pre-Processed Data",
   "id": "ebb8ee365ef0697"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "41ccc1cede84cff5"
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vMGMVkIgF-en",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1740652760840,
     "user_tz": -120,
     "elapsed": 808,
     "user": {
      "displayName": "Dimitris Krikonis",
      "userId": "11139468322740823660"
     }
    },
    "outputId": "3a47fe5c-f36d-4df0-dc35-6a6008ee726f",
    "ExecuteTime": {
     "end_time": "2025-04-14T19:14:07.407006Z",
     "start_time": "2025-04-14T19:14:07.384136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(path + 'agora12_data_pp.csv')\n",
    "data"
   ],
   "id": "2091ea2ebc3ad806",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                               Id  \\\n",
       "0        Agora:Object:Agora XII:1   \n",
       "1        Agora:Object:Agora XII:2   \n",
       "2        Agora:Object:Agora XII:3   \n",
       "3        Agora:Object:Agora XII:4   \n",
       "4        Agora:Object:Agora XII:5   \n",
       "...                           ...   \n",
       "1985  Agora:Object:Agora XII:2036   \n",
       "1986  Agora:Object:Agora XII:2037   \n",
       "1987  Agora:Object:Agora XII:2038   \n",
       "1988  Agora:Object:Agora XII:2039   \n",
       "1989  Agora:Object:Agora XII:2040   \n",
       "\n",
       "                                               FullText  \\\n",
       "0     foot missing. offset neck and echinoid mouth; ...   \n",
       "1     spreading ring foot with torus outer and conve...   \n",
       "2     flaring ring foot. torus mouth. ridge at junct...   \n",
       "3     ring foot. echinoid mouth inset from neck and ...   \n",
       "4     echinus ring foot. torus mouth; strap handles....   \n",
       "...                                                 ...   \n",
       "1985  fragment of rim and floor with handle. deep ba...   \n",
       "1986  handles missing. basin and lid; handles probab...   \n",
       "1987  small series. plain flat-topped rim; flaring b...   \n",
       "1988  small series. rim flat on top, roughly moulded...   \n",
       "1989  stand and floor fragment. lower edge of stand ...   \n",
       "\n",
       "                     ImageFilename  StartYear  EndYear  \n",
       "0     Agora_Image_2012.54.1450.jpg       -575     -550  \n",
       "1                              NaN       -525     -500  \n",
       "2                              NaN       -500     -500  \n",
       "3                              NaN       -500     -500  \n",
       "4     Agora_Image_2012.27.0009.jpg       -525     -500  \n",
       "...                            ...        ...      ...  \n",
       "1985                           NaN       -350     -320  \n",
       "1986  Agora_Image_2012.55.1261.jpg       -350     -301  \n",
       "1987  Agora_Image_2012.25.0184.jpg       -435     -425  \n",
       "1988  Agora_Image_2012.55.1268.jpg       -375     -325  \n",
       "1989                           NaN       -400     -300  \n",
       "\n",
       "[1990 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>FullText</th>\n",
       "      <th>ImageFilename</th>\n",
       "      <th>StartYear</th>\n",
       "      <th>EndYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agora:Object:Agora XII:1</td>\n",
       "      <td>foot missing. offset neck and echinoid mouth; ...</td>\n",
       "      <td>Agora_Image_2012.54.1450.jpg</td>\n",
       "      <td>-575</td>\n",
       "      <td>-550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agora:Object:Agora XII:2</td>\n",
       "      <td>spreading ring foot with torus outer and conve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-525</td>\n",
       "      <td>-500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agora:Object:Agora XII:3</td>\n",
       "      <td>flaring ring foot. torus mouth. ridge at junct...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-500</td>\n",
       "      <td>-500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agora:Object:Agora XII:4</td>\n",
       "      <td>ring foot. echinoid mouth inset from neck and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-500</td>\n",
       "      <td>-500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agora:Object:Agora XII:5</td>\n",
       "      <td>echinus ring foot. torus mouth; strap handles....</td>\n",
       "      <td>Agora_Image_2012.27.0009.jpg</td>\n",
       "      <td>-525</td>\n",
       "      <td>-500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>Agora:Object:Agora XII:2036</td>\n",
       "      <td>fragment of rim and floor with handle. deep ba...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-350</td>\n",
       "      <td>-320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>Agora:Object:Agora XII:2037</td>\n",
       "      <td>handles missing. basin and lid; handles probab...</td>\n",
       "      <td>Agora_Image_2012.55.1261.jpg</td>\n",
       "      <td>-350</td>\n",
       "      <td>-301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>Agora:Object:Agora XII:2038</td>\n",
       "      <td>small series. plain flat-topped rim; flaring b...</td>\n",
       "      <td>Agora_Image_2012.25.0184.jpg</td>\n",
       "      <td>-435</td>\n",
       "      <td>-425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>Agora:Object:Agora XII:2039</td>\n",
       "      <td>small series. rim flat on top, roughly moulded...</td>\n",
       "      <td>Agora_Image_2012.55.1268.jpg</td>\n",
       "      <td>-375</td>\n",
       "      <td>-325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>Agora:Object:Agora XII:2040</td>\n",
       "      <td>stand and floor fragment. lower edge of stand ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-400</td>\n",
       "      <td>-300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1990 rows √ó 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T20:04:33.788384Z",
     "start_time": "2025-04-14T20:04:33.785186Z"
    }
   },
   "cell_type": "code",
   "source": "data = data.astype({'ImageFilename': 'string'})",
   "id": "af824d79ac66b7fe",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature Extraction from Text Data",
   "id": "813c057416017478"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### TF-IDF\n",
    "\n",
    "‚úî **Best for:** Traditional ML models (Random Forest, XGBoost, SVM).\n",
    "\n",
    "‚úî **Why use it?**\n",
    "- Captures word importance across the dataset.\n",
    "- Works well with structured text like archaeological descriptions.\n",
    "- Computationally efficient, doesn‚Äôt require a large dataset.\n",
    "\n",
    "üîπ **Pros:** Fast, interpretable, low resource usage.\n",
    "\n",
    "üîπ **Cons:** Doesn‚Äôt capture word relationships (e.g., \"small bowl\" and \"bowl small\" are treated differently)."
   ],
   "id": "c5a2794b0f4e0eba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:14:08.068628Z",
     "start_time": "2025-04-14T19:14:07.438415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=300,  # Use top 300 important words\n",
    "    stop_words='english'\n",
    ")"
   ],
   "id": "af781d5d5d48a409",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:14:08.155455Z",
     "start_time": "2025-04-14T19:14:08.085874Z"
    }
   },
   "cell_type": "code",
   "source": [
    " # Vectorize the text using TF-IDF\n",
    "tfidf_vectors = vectorizer.fit_transform(data[\"FullText\"]).toarray()\n",
    "\n",
    "# Convert to DataFrame\n",
    "tfidf_vectors = pd.DataFrame(tfidf_vectors, columns=[f\"F{i}\" for i in range(300)])\n",
    "tfidf_vectors"
   ],
   "id": "6d62093f7736be8f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            F0   F1   F2        F3   F4   F5   F6        F7   F8   F9  ...  \\\n",
       "0     0.000000  0.0  0.0  0.112297  0.0  0.0  0.0  0.136783  0.0  0.0  ...   \n",
       "1     0.198781  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
       "2     0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
       "3     0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
       "4     0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
       "...        ...  ...  ...       ...  ...  ...  ...       ...  ...  ...  ...   \n",
       "1985  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
       "1986  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
       "1987  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
       "1988  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
       "1989  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
       "\n",
       "          F290      F291      F292  F293  F294  F295      F296  F297  \\\n",
       "0     0.057870  0.000000  0.000000   0.0   0.0   0.0  0.000000   0.0   \n",
       "1     0.091611  0.000000  0.000000   0.0   0.0   0.0  0.000000   0.0   \n",
       "2     0.150587  0.000000  0.000000   0.0   0.0   0.0  0.000000   0.0   \n",
       "3     0.066499  0.000000  0.000000   0.0   0.0   0.0  0.000000   0.0   \n",
       "4     0.000000  0.000000  0.000000   0.0   0.0   0.0  0.000000   0.0   \n",
       "...        ...       ...       ...   ...   ...   ...       ...   ...   \n",
       "1985  0.000000  0.000000  0.226684   0.0   0.0   0.0  0.000000   0.0   \n",
       "1986  0.000000  0.000000  0.165994   0.0   0.0   0.0  0.000000   0.0   \n",
       "1987  0.000000  0.150721  0.000000   0.0   0.0   0.0  0.000000   0.0   \n",
       "1988  0.000000  0.195492  0.000000   0.0   0.0   0.0  0.000000   0.0   \n",
       "1989  0.085868  0.000000  0.000000   0.0   0.0   0.0  0.161437   0.0   \n",
       "\n",
       "          F298  F299  \n",
       "0     0.000000   0.0  \n",
       "1     0.000000   0.0  \n",
       "2     0.000000   0.0  \n",
       "3     0.000000   0.0  \n",
       "4     0.000000   0.0  \n",
       "...        ...   ...  \n",
       "1985  0.000000   0.0  \n",
       "1986  0.000000   0.0  \n",
       "1987  0.221368   0.0  \n",
       "1988  0.000000   0.0  \n",
       "1989  0.000000   0.0  \n",
       "\n",
       "[1990 rows x 300 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F0</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F290</th>\n",
       "      <th>F291</th>\n",
       "      <th>F292</th>\n",
       "      <th>F293</th>\n",
       "      <th>F294</th>\n",
       "      <th>F295</th>\n",
       "      <th>F296</th>\n",
       "      <th>F297</th>\n",
       "      <th>F298</th>\n",
       "      <th>F299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.198781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.221368</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.195492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.161437</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1990 rows √ó 300 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:14:08.417688Z",
     "start_time": "2025-04-14T19:14:08.274658Z"
    }
   },
   "cell_type": "code",
   "source": "tfidf_vectors.to_csv(path_export + 'text_tfidf_vectors.csv', index=False, encoding='utf-8', sep=',', header=True)",
   "id": "7b4cc7259b0fc3af",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### BERT\n",
    "\n",
    " Pretrained BERT models convert text (pottery descriptions, classifications, and dimensions) into dense numerical embeddings.\n",
    "\n",
    "‚úÖ Pros:\n",
    "- Fast with low compute cost.\n",
    "- Good for small datasets.\n",
    "- Understands context better than TF-IDF\n",
    "- Combines perfectly with images, dimensions, deposits for mixed models.\n",
    "\n",
    "‚ùå Cons:\n",
    "- Doesn‚Äôt adapt BERT to archaeology-specific vocabulary."
   ],
   "id": "f02a85c600e7ad24"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:14:08.435307Z",
     "start_time": "2025-04-14T19:14:08.433312Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ca983b2434b7711",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:14:13.541210Z",
     "start_time": "2025-04-14T19:14:08.646229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import os\n",
    "\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\""
   ],
   "id": "fadec6f2a2728c80",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:14:13.570651Z",
     "start_time": "2025-04-14T19:14:13.550512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())  # True if CUDA is installed\n",
    "print(torch.cuda.get_device_name(0))  # Should show NVIDIA GeForce RTX 4080"
   ],
   "id": "e524ceca40a48782",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n",
      "True\n",
      "NVIDIA GeForce RTX 4080\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "918e6cb3709a4d1c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Load BERT**\n",
    "- \"bert-base-uncased\" is the standard English BERT ‚Äî lowercased, pretrained on Wikipedia and BooksCorpus.\n",
    "- Tokenizer will convert your text into token IDs and attention masks.\n",
    "- Model will turn those token IDs into a vector representation (embedding)."
   ],
   "id": "2c252fe9321d56a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:14:15.225194Z",
     "start_time": "2025-04-14T19:14:13.577655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the tokenizer and BERT model\n",
    "model_name = \"bert-base-uncased\"  # \"sentence-transformers/all-MiniLM-L6-v2\" for optimized embeddings\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ],
   "id": "9087073fe22466d",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Text to BERT Embedding Function**\n",
    "- The function takes raw text and returns a 768-dimensional vector (BERT‚Äôs hidden size).\n",
    "- `tokenizer` converts text to token IDs and attention masks.\n",
    "- `inputs = {key: val.to(\"cuda\")}` moves all input tensors to GPU.\n",
    "- ``model.to(\"cuda\")`` ensures the model uses the GPU too.\n",
    "- ``with torch.no_grad()`` tells PyTorch: no gradients needed (inference mode, not training).\n",
    "- ``outputs.last_hidden_state[:, 0, :]``: grabs the first token‚Äôs embedding ([CLS]) which BERT uses to summarize the whole sequence."
   ],
   "id": "ed7c4db4138e24c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:14:15.239426Z",
     "start_time": "2025-04-14T19:14:15.235288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_bert_embedding_tensor(text):\n",
    "    if pd.isna(text) or text.strip() == \"\":\n",
    "        return torch.zeros(768).to(\"cuda\")  # Fallback for empty text\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "\n",
    "    # Move each tensor in the dict to CUDA\n",
    "    inputs = {key: val.to(\"cuda\") for key, val in inputs.items()}\n",
    "    model.to(\"cuda\")  # Make sure the model is on CUDA too!\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    bert_embedding_tensor = outputs.last_hidden_state[:, 0, :].squeeze()\n",
    "    return bert_embedding_tensor"
   ],
   "id": "909ceebfea595b0f",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**BERT Embedding Tensors**\n",
    "\n",
    "Apply text to BERT embedding tensor transformation to all records"
   ],
   "id": "98496166b1c05f67"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:14:23.960682Z",
     "start_time": "2025-04-14T19:14:15.249018Z"
    }
   },
   "cell_type": "code",
   "source": "bert_embedding_tensor_list = data[\"FullText\"].apply(get_bert_embedding_tensor).tolist()",
   "id": "55684d0fbffdc016",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Stack tensors into single tensor for neural network pipelines",
   "id": "1e3e79e058aed35f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:14:24.102827Z",
     "start_time": "2025-04-14T19:14:24.094473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bert_embedding_tensors = torch.stack(bert_embedding_tensor_list)\n",
    "bert_embedding_tensors.shape"
   ],
   "id": "951c692284889af0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1990, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:14:24.182412Z",
     "start_time": "2025-04-14T19:14:24.173421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.save(bert_embedding_tensors, path_export + \"text_bert_embedding_tensors.pt\")\n",
    "# bert_embedding_tensors = torch.load(path + \"text_bert_embedding_tensors.pt\")"
   ],
   "id": "4559800e6fd8ac71",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**BERT Embedding Vectors**\n",
    "\n",
    "Convert tensors to 2D NumPy Matrix for classic ML methods"
   ],
   "id": "f2ebed39562adc4e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:14:24.274436Z",
     "start_time": "2025-04-14T19:14:24.240084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bert_embedding_vectors = [tensor.cpu().numpy() for tensor in bert_embedding_tensor_list]\n",
    "bert_embedding_vectors = np.vstack(bert_embedding_vectors)\n",
    "bert_embedding_vectors = pd.DataFrame(\n",
    "    bert_embedding_vectors,\n",
    "    columns=[f\"F{i}\" for i in range(bert_embedding_vectors.shape[1])]\n",
    ")\n",
    "bert_embedding_vectors.shape"
   ],
   "id": "fad5bf909709e53a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1990, 768)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:14:24.864780Z",
     "start_time": "2025-04-14T19:14:24.330824Z"
    }
   },
   "cell_type": "code",
   "source": "bert_embedding_vectors.to_csv(path_export + 'text_bert_embedding_vectors.csv', index=False, encoding='utf-8', sep=',',header=True)",
   "id": "a63a2bb94f7e8bb",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Fine-Tuning BERT\n",
    "\n",
    "‚úÖ Pros:\n",
    "- BERT learns from the specific archaeology vocabulary of the data.\n",
    "- Usually higher performance for text-heavy tasks.\n",
    "\n",
    "‚ùå Cons:\n",
    "- Takes longer to train.\n",
    "- Harder to combine with images."
   ],
   "id": "a28822d42febf7de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:14:24.930394Z",
     "start_time": "2025-04-14T19:14:24.928394Z"
    }
   },
   "cell_type": "code",
   "source": "#### TO DO: TRY FINE TUNING ######",
   "id": "ffc804856d7c585",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature Extraction from Images",
   "id": "4dbdb744bde67025"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Pretrained CNNs (Transfer Learning)\n",
    "\n",
    "Pretrained Convolutional Neural Networks (CNNs) trained on ImageNet (millions of images) to extract feature vectors.\n",
    "\n",
    "‚úÖ Pros:\n",
    "- Good for small dataset, no training needed.\n",
    "- Despite being trained on everyday objects, they can recognize visual patterns of pottery like:\n",
    "  - shape contours,\n",
    "  - textures,\n",
    "  - edges and symmetries\n",
    "\n",
    "‚ùå Cons:\n",
    "- Not specialized to archaeological images.\n"
   ],
   "id": "2edb274003f97eb7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### ResNet",
   "id": "c0464e4f8861ceee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:56:20.766884Z",
     "start_time": "2025-04-14T19:56:20.763813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50\n",
    "from PIL import Image"
   ],
   "id": "b7d608b5e35325bf",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Preprocessing Steps for Input Images**\n",
    "\n",
    "- ``transforms.Resize((224, 224))``: Resize to 224x224 pixels (size of images ResNet is trained on)\n",
    "- ``transforms.ToTensor()``: Convert to a PyTorch tensor with pixel values scaled to [0, 1]\n",
    "- ``transforms.Normalize()``: Standardize pixel values using the ImageNet mean and std ‚Äî the same normalization the original ResNet model expects"
   ],
   "id": "ff2f60532905df78"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:56:23.106526Z",
     "start_time": "2025-04-14T19:56:23.104038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resnet_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ],
   "id": "581359c7cb73a760",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Load & Adjust Pretrained ResNet Model**\n",
    "\n",
    "- Load ResNet50 architecture from PyTorch, with default weights trained on ImageNet.\n",
    "- Remove the classification layer (last linear layer), to only use ResNet for feature extraction and not classification.\n",
    "- Set to evaluation/interface mode (no dropout, no batch norm updates) and move to GPU"
   ],
   "id": "4336f7869bde69d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:56:25.066616Z",
     "start_time": "2025-04-14T19:56:24.858334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resnet = resnet50(weights='DEFAULT')\n",
    "resnet = torch.nn.Sequential(*list(resnet.children())[:-1])\n",
    "resnet.eval().cuda()"
   ],
   "id": "2f8d051694f4fcd4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Feature Extraction Process**\n",
    "\n",
    "- Open image and ensure it has 3 channels (RGB)\n",
    "- Apply the preprocessing steps to the image\n",
    "- Add batch dimension, new shape: [1, 3, 224, 224], as ResNet expects its input\n",
    "- Move tensor to GPU\n",
    "- Turn off gradient tracking (faster, uses less memory)\n",
    "- Pass the image through the model to get the feature vector"
   ],
   "id": "64e28d61ed687e4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T20:25:05.651049Z",
     "start_time": "2025-04-14T20:25:05.648012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_resnet_features(image_path):\n",
    "    if not image_path:\n",
    "        return torch.zeros(2048).to(\"cuda\")  # Placeholder for missing images\n",
    "\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image_tensor = resnet_transform(image).unsqueeze(0).cuda()\n",
    "    with torch.no_grad():\n",
    "        features = resnet(image_tensor).squeeze()\n",
    "    return features"
   ],
   "id": "72262b237ce1086b",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T20:25:24.020857Z",
     "start_time": "2025-04-14T20:25:07.527829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resnet_image_tensor_list = []\n",
    "for image_filename in data[\"ImageFilename\"]:\n",
    "    image_path = path_images + image_filename if isinstance(image_filename, str) else ''\n",
    "    resnet_image_tensor_list += [extract_resnet_features(image_path)]"
   ],
   "id": "9622e7976d3b77d3",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T20:25:31.778785Z",
     "start_time": "2025-04-14T20:25:31.774555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resnet_image_tensors = torch.stack(resnet_image_tensor_list)\n",
    "resnet_image_tensors.shape"
   ],
   "id": "69034949f2b8f65b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1990, 2048])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T20:27:48.390871Z",
     "start_time": "2025-04-14T20:27:48.375804Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(resnet_image_tensors, path_export + \"image_resnet_tensors.pt\")",
   "id": "4f6f13d7eae9053a",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T20:25:34.681439Z",
     "start_time": "2025-04-14T20:25:34.616366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resnet_image_vectors = [tensor.cpu().numpy() for tensor in resnet_image_tensor_list]\n",
    "resnet_image_vectors = np.vstack(resnet_image_vectors)\n",
    "resnet_image_vectors = pd.DataFrame(\n",
    "    resnet_image_vectors,\n",
    "    columns=[f\"F{i}\" for i in range(resnet_image_vectors.shape[1])]\n",
    ")\n",
    "resnet_image_vectors.shape"
   ],
   "id": "7b87f0e8aa621d66",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1990, 2048)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T20:25:43.461337Z",
     "start_time": "2025-04-14T20:25:43.452570Z"
    }
   },
   "cell_type": "code",
   "source": "resnet_image_vectors.head()",
   "id": "5e1ed804b2a165c2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    F0        F1        F2   F3        F4        F5        F6   F7        F8  \\\n",
       "0  0.0  0.000000  0.031513  0.0  0.051861  0.008954  0.000000  0.0  0.036491   \n",
       "1  0.0  0.000000  0.000000  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "2  0.0  0.000000  0.000000  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "3  0.0  0.000000  0.000000  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "4  0.0  0.130041  0.000000  0.0  0.005123  0.001841  0.003921  0.0  0.000000   \n",
       "\n",
       "         F9  ...  F2038  F2039  F2040  F2041  F2042  F2043  F2044  F2045  \\\n",
       "0  0.053405  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1  0.000000  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2  0.000000  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3  0.000000  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4  0.052099  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   F2046     F2047  \n",
       "0    0.0  0.000000  \n",
       "1    0.0  0.000000  \n",
       "2    0.0  0.000000  \n",
       "3    0.0  0.000000  \n",
       "4    0.0  0.042308  \n",
       "\n",
       "[5 rows x 2048 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F0</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F2038</th>\n",
       "      <th>F2039</th>\n",
       "      <th>F2040</th>\n",
       "      <th>F2041</th>\n",
       "      <th>F2042</th>\n",
       "      <th>F2043</th>\n",
       "      <th>F2044</th>\n",
       "      <th>F2045</th>\n",
       "      <th>F2046</th>\n",
       "      <th>F2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051861</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036491</td>\n",
       "      <td>0.053405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005123</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 2048 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T20:28:40.192718Z",
     "start_time": "2025-04-14T20:28:39.211915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resnet_image_vectors.to_csv(path_export + 'image_resnet_vectors.csv', index=False, encoding='utf-8', sep=',',\n",
    "                              header=True)"
   ],
   "id": "9173d22d3b6388f8",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Vision Transformers (ViT)\n",
    "\n",
    "Transformer-based model from Hugging Face that treats images like sequences (patches).\n",
    "\n",
    "- advanced alternative\n",
    "- modern / cutting-edge method\n",
    "\n"
   ],
   "id": "8794e6d45191280"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "521ebfe667d42261"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Fine-Tuning Pretrained CNNs (End-to-End Training)\n",
    "\n",
    "‚úÖ Pros:\n",
    "- Learns specifically from images with pottery\n",
    "- Potentially higher accuracy\n",
    "\n",
    "‚ùå Cons:\n",
    "- Requires large dataset and more computing power\n",
    "- Risk of overfitting with only ~500 images.\n",
    "\n"
   ],
   "id": "8ff92b061058e444"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "21fd016741c7077"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
